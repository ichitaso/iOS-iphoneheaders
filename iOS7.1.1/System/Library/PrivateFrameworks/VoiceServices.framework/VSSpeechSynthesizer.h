/*
* This header is generated by classdump-dyld 0.2
* on Sunday, June 29, 2014 at 1:25:51 PM Japan Standard Time
* Operating System: Version 7.1.1 (Build 11D201)
* Image Source: /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices
* classdump-dyld is licensed under GPLv3, Copyright Â© 2013 by Elias Limneos.
*/

#import <VoiceServices/VoiceServices-Structs.h>
#import <VoiceServices/VSSpeechConnectionDelegate.h>

@protocol OS_dispatch_queue, VSSpeechSynthesizerDelegate;
@class VSKeepAlive, NSObject, VSSpeechConnection, NSString;

@interface VSSpeechSynthesizer : NSObject <VSSpeechConnectionDelegate> {

	VSKeepAlive* _keepAlive;
	VSKeepAlive* _inactiveKeepAlive;
	long long _footprint;
	bool _useCustomVoice;
	long long _gender;
	bool _useSharedSession;
	bool _audioSessionIDIsValid;
	unsigned _audioSessionID;
	unsigned _audioQueueFlags;
	NSObject<OS_dispatch_queue>* _queue;
	VSSpeechConnection* _speechConnection;
	struct {
		unsigned delegateStart : 1;
		unsigned delegateFinish : 1;
		unsigned delegateFinishWithPhonemesSpoken : 1;
		unsigned delegatePause : 1;
		unsigned delegateContinue : 1;
		unsigned delegateWillSpeak : 1;
		unsigned delegateStartWithRequest : 1;
		unsigned delegateFinishWithRequest : 1;
		unsigned delegateFinishWithPhonemesSpokenWithRequest : 1;
		unsigned delegatePauseWithRequest : 1;
		unsigned delegateContinueWithRequest : 1;
		unsigned delegateWillSpeakWithRequest : 1;
		unsigned willUseInput : 1;
	}  _synthesizerFlags;
	float _rate;
	float _pitch;
	float _volume;
	<VSSpeechSynthesizerDelegate>* _delegate;
	NSString* _voice;

}

@property (assign,nonatomic,__weak) <VSSpeechSynthesizerDelegate> * delegate;              //@synthesize delegate=_delegate - In the implementation block
@property (assign,nonatomic) float rate;                                                   //@synthesize rate=_rate - In the implementation block
@property (assign,nonatomic) float pitch;                                                  //@synthesize pitch=_pitch - In the implementation block
@property (assign,nonatomic) float volume;                                                 //@synthesize volume=_volume - In the implementation block
@property (nonatomic,retain) NSString * voice;                                             //@synthesize voice=_voice - In the implementation block
+(void)setAutoDownloadedVoiceAssets:(id)arg1 ;
+(void)getAutoDownloadedVoiceAssets:(/*^block*/ id)arg1 ;
+(void)getAllVoiceAssets:(/*^block*/ id)arg1 ;
+(void)getLocalVoiceAssets:(/*^block*/ id)arg1 ;
+(void)downloadVoiceAsset:(id)arg1 progress:(/*^block*/ id)arg2 completion:(/*^block*/ id)arg3 ;
+(void)getVoiceInfoForLanguageCode:(id)arg1 footprint:(long long)arg2 gender:(long long)arg3 custom:(bool)arg4 reply:(/*^block*/ id)arg5 ;
+(id)availableVoicesForLanguageCode:(id)arg1 ;
+(id)availableFootprintsForVoice:(id)arg1 languageCode:(id)arg2 ;
+(bool)isSystemSpeaking;
+(id)availableVoices;
+(id)availableLanguageCodes;
-(void)dealloc;
-(void)setDelegate:(id)arg1 ;
-(id)init;
-(id)delegate;
-(void).cxx_destruct;
-(void)_setDelegate:(id)arg1 ;
-(void)setMaintainInactivePersistentConnection:(bool)arg1 ;
-(float)rate;
-(bool)useCustomVoice;
-(long long)footprint;
-(long long)gender;
-(void)setFootprint:(long long)arg1 ;
-(void)setUseCustomVoice:(bool)arg1 ;
-(void)setGender:(long long)arg1 ;
-(bool)_startSpeakingString:(id)arg1 orAttributedString:(id)arg2 toURL:(id)arg3 withLanguageCode:(id)arg4 request:(id*)arg5 error:(id*)arg6 ;
-(bool)_stopSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 synchronously:(bool)arg3 error:(id*)arg4 ;
-(bool)startSpeakingString:(id)arg1 toURL:(id)arg2 withLanguageCode:(id)arg3 error:(id*)arg4 ;
-(bool)stopSpeakingAtNextBoundary:(long long)arg1 synchronously:(bool)arg2 error:(id*)arg3 ;
-(bool)pauseSpeakingAtNextBoundary:(long long)arg1 synchronously:(bool)arg2 error:(id*)arg3 ;
-(bool)_pauseSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 synchronously:(bool)arg3 error:(id*)arg4 ;
-(bool)_continueSpeakingRequest:(id)arg1 withError:(id*)arg2 ;
-(void)connection:(id)arg1 speechRequestDidStart:(id)arg2 ;
-(void)connection:(id)arg1 speechRequestDidPause:(id)arg2 ;
-(void)connection:(id)arg1 speechRequestDidContinue:(id)arg2 ;
-(void)connection:(id)arg1 speechRequest:(id)arg2 didStopAtEnd:(bool)arg3 phonemesSpoken:(id)arg4 error:(id)arg5 ;
-(void)connection:(id)arg1 speechRequest:(id)arg2 willSpeakMark:(long long)arg3 inRange:(NSRange)arg4 ;
-(bool)startSpeakingAttributedString:(id)arg1 toURL:(id)arg2 withLanguageCode:(id)arg3 error:(id*)arg4 ;
-(bool)startSpeakingString:(id)arg1 error:(id*)arg2 ;
-(bool)startSpeakingString:(id)arg1 toURL:(id)arg2 error:(id*)arg3 ;
-(bool)startSpeakingString:(id)arg1 withLanguageCode:(id)arg2 error:(id*)arg3 ;
-(bool)stopSpeakingAtNextBoundary:(long long)arg1 error:(id*)arg2 ;
-(bool)pauseSpeakingAtNextBoundary:(long long)arg1 error:(id*)arg2 ;
-(bool)continueSpeakingWithError:(id*)arg1 ;
-(bool)isSpeaking;
-(id)speechString;
-(float)minimumRate;
-(float)maximumRate;
-(id)voice;
-(void)useSharedAudioSession:(bool)arg1 ;
-(void)useSpecificAudioSession:(unsigned)arg1 ;
-(void)useAudioQueueFlags:(unsigned)arg1 ;
-(bool)startSpeakingString:(id)arg1 request:(id*)arg2 error:(id*)arg3 ;
-(bool)startSpeakingString:(id)arg1 toURL:(id)arg2 request:(id*)arg3 error:(id*)arg4 ;
-(bool)startSpeakingString:(id)arg1 withLanguageCode:(id)arg2 request:(id*)arg3 error:(id*)arg4 ;
-(bool)stopSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 error:(id*)arg3 ;
-(bool)stopSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 synchronously:(bool)arg3 error:(id*)arg4 ;
-(bool)pauseSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 error:(id*)arg3 ;
-(bool)pauseSpeakingRequest:(id)arg1 atNextBoundary:(long long)arg2 synchronously:(bool)arg3 error:(id*)arg4 ;
-(bool)continueSpeakingRequest:(id)arg1 withError:(id*)arg2 ;
-(id)initForInputFeedback;
-(void)setMaintainPersistentConnection:(bool)arg1 ;
-(float)pitch;
-(void)setPitch:(float)arg1 ;
-(float)volume;
-(void)setVolume:(float)arg1 ;
-(void)setRate:(float)arg1 ;
-(void)setVoice:(id)arg1 ;
@end

